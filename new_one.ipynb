{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, LSTM, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(file_paths):\n",
    "    print(\"Loading data...\")\n",
    "    dfs = []\n",
    "    for file_path in file_paths:\n",
    "        df = pd.read_csv(file_path)\n",
    "        dfs.append(df)\n",
    "    \n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    labels_to_remove = ['DictionaryBruteForce', 'BrowserHijacking', 'XSS', \n",
    "                        'Uploading_Attack', 'SqlInjection', 'CommandInjection', \n",
    "                        'Backdoor_Malware']\n",
    "    df = df[~df['label'].isin(labels_to_remove)]\n",
    "    \n",
    "    print(\"\\nOriginal class distribution:\")\n",
    "    print(df['label'].value_counts())\n",
    "    \n",
    "    columns_to_drop = ['label', 'flow_id', 'src_ip', 'src_port', \n",
    "                       'dst_ip', 'dst_port', 'protocol', 'timestamp']\n",
    "    columns_to_drop = [col for col in columns_to_drop if col in df.columns]\n",
    "    \n",
    "    X = df.drop(columns_to_drop, axis=1)\n",
    "    y = df['label']\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "    \n",
    "    return X, y, le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_dataset(X, y, strategy='hybrid', random_state=42):\n",
    "    print(\"\\nOriginal dataset shape:\", Counter(y))\n",
    "    \n",
    "    if strategy == 'smote':\n",
    "        sampler = SMOTE(random_state=random_state)\n",
    "        X_resampled, y_resampled = sampler.fit_resample(X, y)\n",
    "    elif strategy == 'adasyn':\n",
    "        sampler = ADASYN(random_state=random_state)\n",
    "        X_resampled, y_resampled = sampler.fit_resample(X, y)\n",
    "    elif strategy == 'hybrid':\n",
    "        class_counts = Counter(y)\n",
    "        median_count = np.median(list(class_counts.values()))\n",
    "        mean_count = np.mean(list(class_counts.values()))\n",
    "        target_count = int((median_count + mean_count) / 2)\n",
    "        \n",
    "        sampling_strategy_over = {k: target_count for k, v in class_counts.items() \n",
    "                                  if v < target_count}\n",
    "        sampling_strategy_under = {k: target_count for k, v in class_counts.items() \n",
    "                                   if v > target_count}\n",
    "        \n",
    "        pipeline = Pipeline([\n",
    "            ('smote', SMOTE(sampling_strategy=sampling_strategy_over, \n",
    "                            random_state=random_state)),\n",
    "            ('undersampler', RandomUnderSampler(sampling_strategy=sampling_strategy_under, \n",
    "                                                random_state=random_state))\n",
    "        ])\n",
    "        \n",
    "        X_resampled, y_resampled = pipeline.fit_resample(X, y)\n",
    "    \n",
    "    print(\"Balanced dataset shape:\", Counter(y_resampled))\n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_data_for_training(X, y, test_size=0.2, val_size=0.2, random_state=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=val_size, random_state=random_state, stratify=y_train\n",
    "    )\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    num_classes = len(np.unique(y))\n",
    "    y_train_cat = to_categorical(y_train, num_classes)\n",
    "    y_val_cat = to_categorical(y_val, num_classes)\n",
    "    y_test_cat = to_categorical(y_test, num_classes)\n",
    "    \n",
    "    return (X_train_scaled, X_val_scaled, X_test_scaled,\n",
    "            y_train_cat, y_val_cat, y_test_cat,\n",
    "            scaler, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_train_model(X_train, y_train, X_val, y_val, num_classes):\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "    X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], 1)\n",
    "    \n",
    "    model = Sequential([\n",
    "        Conv1D(64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Conv1D(128, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Conv1D(256, kernel_size=3, activation='relu'),\n",
    "        Bidirectional(LSTM(64, return_sequences=True)),\n",
    "        Bidirectional(LSTM(32)),\n",
    "        Dense(256, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "        Dropout(0.2),\n",
    "        Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "        Dropout(0.2),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "        Dropout(0.2),\n",
    "        Dense(num_classes, activation='softmax')  \n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(X_train, y_train,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        epochs=200,\n",
    "                        batch_size=32,\n",
    "                        verbose=1)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, le):\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_test_classes = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
    "    precision = precision_score(y_test_classes, y_pred_classes, average='weighted')\n",
    "    recall = recall_score(y_test_classes, y_pred_classes, average='weighted')\n",
    "    f1 = f1_score(y_test_classes, y_pred_classes, average='weighted')\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test_classes, y_pred_classes, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, scaler, le, model_dir='saveded_model'):\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    \n",
    "    model.save(os.path.join(model_dir, 'ddos_model.h5'))\n",
    "    joblib.dump(scaler, os.path.join(model_dir, 'scaler.joblib'))\n",
    "    joblib.dump(le, os.path.join(model_dir, 'label_encoder.joblib'))\n",
    "    print(f\"Model and associated objects saved in {model_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_saved_model(model_dir='saveded_model'):\n",
    "    model = load_model(os.path.join(model_dir, 'ddos_model.h5'))\n",
    "    scaler = joblib.load(os.path.join(model_dir, 'scaler.joblib'))\n",
    "    le = joblib.load(os.path.join(model_dir, 'label_encoder.joblib'))\n",
    "    print(f\"Model and associated objects loaded from {model_dir}\")\n",
    "    return model, scaler, le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loaded_model(model, scaler, le, X_test, y_test):\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    X_test_scaled = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)\n",
    "    \n",
    "    # Ensure y_test is in categorical format\n",
    "    if len(y_test.shape) == 1 or y_test.shape[1] == 1:\n",
    "        y_test_cat = to_categorical(y_test, num_classes=len(le.classes_))\n",
    "    else:\n",
    "        y_test_cat = y_test\n",
    "    \n",
    "    print(\"Evaluating loaded model:\")\n",
    "    evaluate_model(model, X_test_scaled, y_test_cat, le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\n",
      "Original class distribution:\n",
      "label\n",
      "DDoS-ICMP_Flood            112423\n",
      "DDoS-UDP_Flood              84712\n",
      "DDoS-TCP_Flood              70630\n",
      "DDoS-PSHACK_Flood           64473\n",
      "DDoS-SYN_Flood              64137\n",
      "DDoS-RSTFINFlood            63524\n",
      "DDoS-SynonymousIP_Flood     56428\n",
      "DoS-UDP_Flood               52059\n",
      "DoS-TCP_Flood               41894\n",
      "DoS-SYN_Flood               31595\n",
      "BenignTraffic               17187\n",
      "Mirai-greeth_flood          15447\n",
      "Mirai-udpplain              14213\n",
      "Mirai-greip_flood           11873\n",
      "DDoS-ICMP_Fragmentation      7194\n",
      "MITM-ArpSpoofing             4881\n",
      "DDoS-UDP_Fragmentation       4568\n",
      "DDoS-ACK_Fragmentation       4524\n",
      "DNS_Spoofing                 2822\n",
      "Recon-HostDiscovery          2165\n",
      "Recon-OSScan                 1517\n",
      "Recon-PortScan               1311\n",
      "DoS-HTTP_Flood               1215\n",
      "VulnerabilityScan             560\n",
      "DDoS-HTTP_Flood               442\n",
      "DDoS-SlowLoris                337\n",
      "Recon-PingSweep                26\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Original dataset shape: Counter({3: 112423, 11: 84712, 10: 70630, 5: 64473, 7: 64137, 6: 63524, 9: 56428, 17: 52059, 16: 41894, 15: 31595, 0: 17187, 19: 15447, 21: 14213, 20: 11873, 4: 7194, 18: 4881, 12: 4568, 1: 4524, 13: 2822, 22: 2165, 23: 1517, 25: 1311, 14: 1215, 26: 560, 2: 442, 8: 337, 24: 26})\n",
      "Balanced dataset shape: Counter({0: 19494, 1: 19494, 2: 19494, 3: 19494, 4: 19494, 5: 19494, 6: 19494, 7: 19494, 8: 19494, 9: 19494, 10: 19494, 11: 19494, 12: 19494, 13: 19494, 14: 19494, 15: 19494, 16: 19494, 17: 19494, 18: 19494, 19: 19494, 20: 19494, 21: 19494, 22: 19494, 23: 19494, 24: 19494, 25: 19494, 26: 19494})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\ddos\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 11ms/step - accuracy: 0.5922 - loss: 1.1209 - val_accuracy: 0.7418 - val_loss: 0.6371\n",
      "Epoch 2/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 11ms/step - accuracy: 0.7448 - loss: 0.6295 - val_accuracy: 0.7628 - val_loss: 0.5663\n",
      "Epoch 3/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 11ms/step - accuracy: 0.7596 - loss: 0.5784 - val_accuracy: 0.7622 - val_loss: 0.6313\n",
      "Epoch 4/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 11ms/step - accuracy: 0.7678 - loss: 0.5534 - val_accuracy: 0.7708 - val_loss: 0.5266\n",
      "Epoch 5/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 11ms/step - accuracy: 0.7742 - loss: 0.5338 - val_accuracy: 0.7782 - val_loss: 0.5249\n",
      "Epoch 6/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 11ms/step - accuracy: 0.7816 - loss: 0.5176 - val_accuracy: 0.7809 - val_loss: 0.5033\n",
      "Epoch 7/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 11ms/step - accuracy: 0.7831 - loss: 0.5120 - val_accuracy: 0.7909 - val_loss: 0.4934\n",
      "Epoch 8/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 11ms/step - accuracy: 0.7866 - loss: 0.5025 - val_accuracy: 0.7907 - val_loss: 0.4895\n",
      "Epoch 9/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 11ms/step - accuracy: 0.7892 - loss: 0.4939 - val_accuracy: 0.7919 - val_loss: 0.4847\n",
      "Epoch 10/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 11ms/step - accuracy: 0.7910 - loss: 0.4911 - val_accuracy: 0.7890 - val_loss: 0.4889\n",
      "Epoch 11/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 11ms/step - accuracy: 0.8030 - loss: 0.4794 - val_accuracy: 0.8271 - val_loss: 0.4450\n",
      "Epoch 12/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 11ms/step - accuracy: 0.8135 - loss: 0.4660 - val_accuracy: 0.8269 - val_loss: 0.4506\n",
      "Epoch 13/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 11ms/step - accuracy: 0.8178 - loss: 0.4577 - val_accuracy: 0.8329 - val_loss: 0.4371\n",
      "Epoch 14/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 11ms/step - accuracy: 0.8293 - loss: 0.4421 - val_accuracy: 0.8353 - val_loss: 0.4277\n",
      "Epoch 15/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 11ms/step - accuracy: 0.8335 - loss: 0.4321 - val_accuracy: 0.7993 - val_loss: 0.4580\n",
      "Epoch 16/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 12ms/step - accuracy: 0.8309 - loss: 0.4348 - val_accuracy: 0.8340 - val_loss: 0.4235\n",
      "Epoch 17/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 11ms/step - accuracy: 0.8321 - loss: 0.4321 - val_accuracy: 0.8361 - val_loss: 0.4163\n",
      "Epoch 18/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 11ms/step - accuracy: 0.8363 - loss: 0.4223 - val_accuracy: 0.8333 - val_loss: 0.4293\n",
      "Epoch 19/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 11ms/step - accuracy: 0.8345 - loss: 0.4283 - val_accuracy: 0.8316 - val_loss: 0.4322\n",
      "Epoch 20/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 11ms/step - accuracy: 0.8413 - loss: 0.4133 - val_accuracy: 0.8345 - val_loss: 0.4247\n",
      "Epoch 21/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 11ms/step - accuracy: 0.8414 - loss: 0.4106 - val_accuracy: 0.8370 - val_loss: 0.4178\n",
      "Epoch 22/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 11ms/step - accuracy: 0.8396 - loss: 0.4149 - val_accuracy: 0.8346 - val_loss: 0.4228\n",
      "Epoch 23/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 11ms/step - accuracy: 0.8418 - loss: 0.4108 - val_accuracy: 0.8377 - val_loss: 0.4200\n",
      "Epoch 24/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 19ms/step - accuracy: 0.8434 - loss: 0.4059 - val_accuracy: 0.8471 - val_loss: 0.4324\n",
      "Epoch 25/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 29ms/step - accuracy: 0.8443 - loss: 0.4054 - val_accuracy: 0.8312 - val_loss: 0.4209\n",
      "Epoch 26/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 28ms/step - accuracy: 0.8449 - loss: 0.4044 - val_accuracy: 0.8399 - val_loss: 0.4114\n",
      "Epoch 27/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 30ms/step - accuracy: 0.8429 - loss: 0.4079 - val_accuracy: 0.8401 - val_loss: 0.4133\n",
      "Epoch 28/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 30ms/step - accuracy: 0.8448 - loss: 0.4058 - val_accuracy: 0.8385 - val_loss: 0.4214\n",
      "Epoch 29/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 30ms/step - accuracy: 0.8468 - loss: 0.3993 - val_accuracy: 0.8540 - val_loss: 0.4063\n",
      "Epoch 30/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 29ms/step - accuracy: 0.8479 - loss: 0.3971 - val_accuracy: 0.8388 - val_loss: 0.4112\n",
      "Epoch 31/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 30ms/step - accuracy: 0.8475 - loss: 0.3998 - val_accuracy: 0.8416 - val_loss: 0.4113\n",
      "Epoch 32/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 30ms/step - accuracy: 0.8459 - loss: 0.4009 - val_accuracy: 0.8426 - val_loss: 0.4117\n",
      "Epoch 33/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 24ms/step - accuracy: 0.8464 - loss: 0.3987 - val_accuracy: 0.8395 - val_loss: 0.4198\n",
      "Epoch 34/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 11ms/step - accuracy: 0.8466 - loss: 0.3993 - val_accuracy: 0.8429 - val_loss: 0.4175\n",
      "Epoch 35/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 11ms/step - accuracy: 0.8500 - loss: 0.3938 - val_accuracy: 0.8326 - val_loss: 0.4652\n",
      "Epoch 36/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 11ms/step - accuracy: 0.8472 - loss: 0.4025 - val_accuracy: 0.8320 - val_loss: 0.4212\n",
      "Epoch 37/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 11ms/step - accuracy: 0.8500 - loss: 0.3930 - val_accuracy: 0.8423 - val_loss: 0.4040\n",
      "Epoch 38/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 11ms/step - accuracy: 0.8510 - loss: 0.3925 - val_accuracy: 0.8546 - val_loss: 0.3994\n",
      "Epoch 39/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 11ms/step - accuracy: 0.8538 - loss: 0.3896 - val_accuracy: 0.8346 - val_loss: 0.4254\n",
      "Epoch 40/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 11ms/step - accuracy: 0.8529 - loss: 0.3889 - val_accuracy: 0.8279 - val_loss: 0.4346\n",
      "Epoch 41/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 11ms/step - accuracy: 0.8512 - loss: 0.3920 - val_accuracy: 0.8407 - val_loss: 0.4166\n",
      "Epoch 42/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 11ms/step - accuracy: 0.8522 - loss: 0.3915 - val_accuracy: 0.8390 - val_loss: 0.4216\n",
      "Epoch 43/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 11ms/step - accuracy: 0.8549 - loss: 0.3865 - val_accuracy: 0.8475 - val_loss: 0.4228\n",
      "Epoch 44/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 11ms/step - accuracy: 0.8540 - loss: 0.3904 - val_accuracy: 0.8405 - val_loss: 0.4131\n",
      "Epoch 45/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 11ms/step - accuracy: 0.8487 - loss: 0.3985 - val_accuracy: 0.8417 - val_loss: 0.4134\n",
      "Epoch 46/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 11ms/step - accuracy: 0.8546 - loss: 0.3888 - val_accuracy: 0.8331 - val_loss: 0.4378\n",
      "Epoch 47/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 11ms/step - accuracy: 0.8491 - loss: 0.3974 - val_accuracy: 0.8429 - val_loss: 0.4117\n",
      "Epoch 48/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 11ms/step - accuracy: 0.8562 - loss: 0.3879 - val_accuracy: 0.8342 - val_loss: 0.4345\n",
      "Epoch 49/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 11ms/step - accuracy: 0.8582 - loss: 0.3836 - val_accuracy: 0.8401 - val_loss: 0.4247\n",
      "Epoch 50/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 11ms/step - accuracy: 0.8554 - loss: 0.3860 - val_accuracy: 0.8344 - val_loss: 0.4177\n",
      "Epoch 51/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 14ms/step - accuracy: 0.8523 - loss: 0.3947 - val_accuracy: 0.8786 - val_loss: 0.3681\n",
      "Epoch 52/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 24ms/step - accuracy: 0.8585 - loss: 0.3869 - val_accuracy: 0.8472 - val_loss: 0.4193\n",
      "Epoch 53/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 12ms/step - accuracy: 0.8550 - loss: 0.3922 - val_accuracy: 0.8914 - val_loss: 0.3354\n",
      "Epoch 54/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 11ms/step - accuracy: 0.8849 - loss: 0.3460 - val_accuracy: 0.9091 - val_loss: 0.3015\n",
      "Epoch 55/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 11ms/step - accuracy: 0.9000 - loss: 0.3167 - val_accuracy: 0.9031 - val_loss: 0.3105\n",
      "Epoch 56/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 11ms/step - accuracy: 0.8979 - loss: 0.3250 - val_accuracy: 0.9188 - val_loss: 0.2741\n",
      "Epoch 57/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 11ms/step - accuracy: 0.9056 - loss: 0.3040 - val_accuracy: 0.9150 - val_loss: 0.2911\n",
      "Epoch 58/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 11ms/step - accuracy: 0.9042 - loss: 0.3096 - val_accuracy: 0.9024 - val_loss: 0.3085\n",
      "Epoch 59/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 11ms/step - accuracy: 0.9101 - loss: 0.2992 - val_accuracy: 0.9090 - val_loss: 0.2985\n",
      "Epoch 60/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 11ms/step - accuracy: 0.9096 - loss: 0.3017 - val_accuracy: 0.9180 - val_loss: 0.2715\n",
      "Epoch 61/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 11ms/step - accuracy: 0.9140 - loss: 0.2897 - val_accuracy: 0.9200 - val_loss: 0.2702\n",
      "Epoch 62/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 11ms/step - accuracy: 0.9040 - loss: 0.3118 - val_accuracy: 0.9160 - val_loss: 0.2915\n",
      "Epoch 63/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 11ms/step - accuracy: 0.9114 - loss: 0.2980 - val_accuracy: 0.9172 - val_loss: 0.2827\n",
      "Epoch 64/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 11ms/step - accuracy: 0.9156 - loss: 0.2845 - val_accuracy: 0.9200 - val_loss: 0.2662\n",
      "Epoch 65/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 11ms/step - accuracy: 0.9178 - loss: 0.2771 - val_accuracy: 0.9170 - val_loss: 0.2793\n",
      "Epoch 66/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 11ms/step - accuracy: 0.9186 - loss: 0.2765 - val_accuracy: 0.9081 - val_loss: 0.3200\n",
      "Epoch 67/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 11ms/step - accuracy: 0.9155 - loss: 0.2841 - val_accuracy: 0.9192 - val_loss: 0.2658\n",
      "Epoch 68/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 11ms/step - accuracy: 0.9164 - loss: 0.2809 - val_accuracy: 0.9149 - val_loss: 0.2773\n",
      "Epoch 69/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 11ms/step - accuracy: 0.9163 - loss: 0.2789 - val_accuracy: 0.9175 - val_loss: 0.2751\n",
      "Epoch 70/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 12ms/step - accuracy: 0.9111 - loss: 0.2976 - val_accuracy: 0.9115 - val_loss: 0.2977\n",
      "Epoch 71/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 12ms/step - accuracy: 0.9159 - loss: 0.2843 - val_accuracy: 0.9115 - val_loss: 0.2935\n",
      "Epoch 72/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 12ms/step - accuracy: 0.9174 - loss: 0.2755 - val_accuracy: 0.9191 - val_loss: 0.2722\n",
      "Epoch 73/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 12ms/step - accuracy: 0.9186 - loss: 0.2744 - val_accuracy: 0.9175 - val_loss: 0.2733\n",
      "Epoch 74/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 12ms/step - accuracy: 0.9170 - loss: 0.2768 - val_accuracy: 0.8780 - val_loss: 0.3926\n",
      "Epoch 75/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 12ms/step - accuracy: 0.9149 - loss: 0.2864 - val_accuracy: 0.9174 - val_loss: 0.2722\n",
      "Epoch 76/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 12ms/step - accuracy: 0.9108 - loss: 0.2953 - val_accuracy: 0.9178 - val_loss: 0.2761\n",
      "Epoch 77/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 12ms/step - accuracy: 0.9153 - loss: 0.2847 - val_accuracy: 0.9186 - val_loss: 0.2657\n",
      "Epoch 78/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 12ms/step - accuracy: 0.9155 - loss: 0.2808 - val_accuracy: 0.9178 - val_loss: 0.2691\n",
      "Epoch 79/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 12ms/step - accuracy: 0.9174 - loss: 0.2767 - val_accuracy: 0.8742 - val_loss: 0.3708\n",
      "Epoch 80/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 12ms/step - accuracy: 0.8814 - loss: 0.3576 - val_accuracy: 0.8957 - val_loss: 0.3398\n",
      "Epoch 81/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 12ms/step - accuracy: 0.8707 - loss: 0.3830 - val_accuracy: 0.9000 - val_loss: 0.3206\n",
      "Epoch 82/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 12ms/step - accuracy: 0.8739 - loss: 0.3782 - val_accuracy: 0.8881 - val_loss: 0.3471\n",
      "Epoch 83/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3095s\u001b[0m 294ms/step - accuracy: 0.8575 - loss: 0.4086 - val_accuracy: 0.8365 - val_loss: 0.4268\n",
      "Epoch 84/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 12ms/step - accuracy: 0.8521 - loss: 0.4156 - val_accuracy: 0.8576 - val_loss: 0.4006\n",
      "Epoch 85/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 12ms/step - accuracy: 0.8801 - loss: 0.3722 - val_accuracy: 0.8413 - val_loss: 0.4291\n",
      "Epoch 86/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 12ms/step - accuracy: 0.8761 - loss: 0.3786 - val_accuracy: 0.9024 - val_loss: 0.3232\n",
      "Epoch 87/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 17ms/step - accuracy: 0.8852 - loss: 0.3650 - val_accuracy: 0.9009 - val_loss: 0.3197\n",
      "Epoch 88/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 33ms/step - accuracy: 0.8869 - loss: 0.3580 - val_accuracy: 0.8604 - val_loss: 0.3692\n",
      "Epoch 89/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 33ms/step - accuracy: 0.8864 - loss: 0.3604 - val_accuracy: 0.8891 - val_loss: 0.3564\n",
      "Epoch 90/200\n",
      "\u001b[1m10527/10527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8891 - loss: 0.3573"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    file_paths = [f\"D:\\\\DDOS\\\\New\\\\archive(4)\\\\wataiData\\\\csv\\\\CICIoT2023\\\\part-{i:05d}-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\" \n",
    "                  for i in range(3)]\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    X, y, le = load_and_preprocess_data(file_paths)\n",
    "    \n",
    "    # Balance dataset\n",
    "    X_balanced, y_balanced = balance_dataset(X, y, strategy='hybrid')\n",
    "    \n",
    "    # Prepare data for training\n",
    "    (X_train_scaled, X_val_scaled, X_test_scaled,\n",
    "     y_train_cat, y_val_cat, y_test_cat,\n",
    "     scaler, X_test, y_test) = prepare_data_for_training(X_balanced, y_balanced)\n",
    "    \n",
    "    # Create and train model\n",
    "    num_classes = len(np.unique(y_balanced))\n",
    "    model, history = create_and_train_model(\n",
    "        X_train_scaled, y_train_cat,\n",
    "        X_val_scaled, y_val_cat,\n",
    "        num_classes\n",
    "    )\n",
    "    \n",
    "    # Save model and components\n",
    "    save_model(model, scaler, le)\n",
    "    \n",
    "    # Load and test model\n",
    "    loaded_model, loaded_scaler, loaded_le = load_saved_model()\n",
    "    test_loaded_model(loaded_model, loaded_scaler, loaded_le, \n",
    "                      X_test, y_test)\n",
    "    \n",
    "    # Print final evaluation\n",
    "    print(\"\\nFinal model evaluation:\")\n",
    "    evaluate_model(model, X_test_scaled, y_test_cat, le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
